{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb96483e-640a-4fdd-9802-74e7d5e66f56",
   "metadata": {},
   "source": [
    "# Notebook 01 · Batch Lakehouse Pipeline: Bronze → Silver → Gold\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook builds the core batch data pipeline for FunnelPulse. It takes raw e-commerce event logs for October and November, and turns them into a layered lakehouse:\n",
    "\n",
    "- **Bronze**: Raw event store, normalized and partitioned for scalable access  \n",
    "- **Silver**: Clean, deduplicated, analytics ready events  \n",
    "- **Gold**: Aggregated funnel metrics for different business views  \n",
    "\n",
    "All later components of the system, including streaming and anomaly detection, depend on the tables created here.\n",
    "\n",
    "---\n",
    "\n",
    "## Input Data\n",
    "\n",
    "**Source dataset**\n",
    "\n",
    "- Kaggle: *eCommerce Events History in Cosmetics Shop*  \n",
    "- Raw files provided as monthly CSVs (for example `2019-Oct.csv`, `2019-Nov.csv`)  \n",
    "- Each row represents a product level user interaction with fields such as:\n",
    "  - `event_time`, `event_type` (view, cart, purchase, etc.)\n",
    "  - `user_id`, `user_session`\n",
    "  - `product_id`, `category_id`, `category_code`, `brand`\n",
    "  - `price`\n",
    "\n",
    "**Scope in this notebook**\n",
    "\n",
    "- Ingests data for **October and November**  \n",
    "- Uses incremental month by month ingestion so the design mirrors production where new data arrives continuously\n",
    "\n",
    "---\n",
    "\n",
    "## High Level Workflow\n",
    "\n",
    "1. **Environment and project paths**\n",
    "   - Initialize a Spark session following the course setup\n",
    "   - Define the project root and key directories:\n",
    "     - `data_raw/` for temporary CSV uploads\n",
    "     - `tables/` for Parquet based lakehouse tables\n",
    "\n",
    "2. **Bronze creation (incremental)**\n",
    "   - Ingest one month of raw CSV events at a time  \n",
    "   - Convert time fields and derive partitioning keys  \n",
    "   - Append each month into a unified bronze table\n",
    "\n",
    "3. **Silver creation**\n",
    "   - Read all bronze events for October and November  \n",
    "   - Apply cleaning, normalization and deduplication  \n",
    "   - Write a partitioned silver table suitable for analytical queries\n",
    "\n",
    "4. **Gold creation**\n",
    "   - Read the silver table  \n",
    "   - Build the first core gold table:\n",
    "     - Hourly funnel metrics grouped by brand\n",
    "\n",
    "5. **Sanity checks and sample analytics**\n",
    "   - Inspect schema and sample rows\n",
    "   - Run simple summary queries to verify that metrics and relationships look reasonable\n",
    "\n",
    "---\n",
    "\n",
    "## Bronze Layer · Raw Event Store\n",
    "\n",
    "**What it represents**\n",
    "\n",
    "The bronze layer is the first structured storage of raw events. It is designed to look like the landing zone of a production data platform:\n",
    "\n",
    "- Rows are close to the original Kaggle schema\n",
    "- Only basic normalization is applied so that downstream jobs have a consistent starting point\n",
    "\n",
    "**Key actions in this notebook**\n",
    "\n",
    "- Read a single month CSV from `data_raw/`\n",
    "- Cast `event_time` from string into a timestamp type\n",
    "- Derive `event_date` as the calendar date of `event_time`\n",
    "- Write all events into `tables/bronze_events` as Parquet\n",
    "  - Use `event_date` as a partition column\n",
    "  - Use **append** mode so multiple months can be ingested incrementally\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Partitioning by date makes later scans efficient as the dataset grows\n",
    "- Incremental ingestion models a production feed where new days or months arrive continuously\n",
    "- Bronze is the single source of truth for historical event logs in the platform\n",
    "\n",
    "---\n",
    "\n",
    "## Silver Layer · Cleaned and Analytics Ready Events\n",
    "\n",
    "**What it represents**\n",
    "\n",
    "The silver layer standardizes and cleans data from bronze so that analytical and machine learning workloads do not have to handle raw quirks directly.\n",
    "\n",
    "**Key transformations**\n",
    "\n",
    "- **Filtering**\n",
    "  - Remove rows with missing or non positive prices\n",
    "  - Remove rows with missing `event_time` or `event_type`\n",
    "- **Normalization**\n",
    "  - Create `brand_norm` as a lowercased version of `brand`\n",
    "  - Create `category_code_norm` as a sanitized, lowercased version of `category_code` that is safe to use as a dimension\n",
    "- **Data quality flags**\n",
    "  - Mark events with missing session, brand or category fields\n",
    "- **Deduplication**\n",
    "  - Drop exact duplicates using a composite key of:\n",
    "    - `event_time`, `user_id`, `user_session`, `product_id`, `event_type`\n",
    "- **Storage**\n",
    "  - Write clean events to `tables/silver_events` as Parquet\n",
    "  - Partition by `event_date` for scalable time based access\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- Silver provides a stable, trusted event table that downstream jobs can rely on\n",
    "- It separates raw ingestion concerns from analytical modeling concerns\n",
    "- The deduped, normalized schema is the basis for all funnel and anomaly logic\n",
    "\n",
    "---\n",
    "\n",
    "## Gold Layer · Hourly Funnel Metrics by Brand\n",
    "\n",
    "**What it represents**\n",
    "\n",
    "Gold tables hold pre aggregated metrics tailored to specific business questions. In this notebook we build the first and most important one:\n",
    "\n",
    "- **`gold_funnel_hourly_brand`**  \n",
    "  - Grain: one brand per one hour window  \n",
    "  - Metrics:\n",
    "    - `views`           number of view events  \n",
    "    - `carts`           number of cart events  \n",
    "    - `purchases`       number of purchase events  \n",
    "    - `revenue`         total purchase value in that hour  \n",
    "    - `view_to_cart_rate`      carts per view  \n",
    "    - `cart_to_purchase_rate`  purchases per cart  \n",
    "    - `conversion_rate`        purchases per view  \n",
    "  - Partitioned by `window_date` for efficient access by day\n",
    "\n",
    "**Workflow**\n",
    "\n",
    "- Read `silver_events`\n",
    "- Group events by:\n",
    "  - 1 hour window on `event_time`\n",
    "  - `brand_norm`\n",
    "- Aggregate counts and revenue\n",
    "- Derive funnel rates with protection against divide by zero\n",
    "- Store the results as a gold table in `tables/gold_funnel_hourly_brand`\n",
    "\n",
    "**Why this matters**\n",
    "\n",
    "- This table is the backbone of FunnelPulse\n",
    "- It is the input for both:\n",
    "  - Descriptive funnel analytics in dashboards\n",
    "  - Anomaly detection and alerting logic in later notebooks\n",
    "- It gives an executive ready view of how each brand is performing in near real time at hourly resolution\n",
    "\n",
    "---\n",
    "\n",
    "## Role of This Notebook in the Overall System\n",
    "\n",
    "This notebook is the **foundation of the entire project**:\n",
    "\n",
    "- It turns raw CSV logs into a structured lakehouse with bronze, silver and gold layers\n",
    "- It defines the core funnel metrics that the rest of the system depends on\n",
    "- It prepares data for:\n",
    "  - Additional gold tables (daily by brand, category, price band)  \n",
    "  - Streaming pipelines that compute the same metrics over a simulated real time feed  \n",
    "  - Anomaly detection on top of hourly conversion behavior  \n",
    "\n",
    "All subsequent notebooks build on top of the tables created here rather than going back to the raw CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64eee972-be86-48bd-bde3-b42bc092d81e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/11/27 07:25:16 WARN Utils: Your hostname, Aranyas-Laptop.local, resolves to a loopback address: 127.0.0.1; using 192.168.1.180 instead (on interface en0)\n",
      "25/11/27 07:25:16 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/11/27 07:25:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pyspark.sql.session.SparkSession object at 0x122512720>\n",
      "Spark UI available at: http://localhost:4040\n"
     ]
    }
   ],
   "source": [
    "# CELL 1: Spark initialization for local development\n",
    "# Works on macOS/Linux without JupyterHub\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Set JAVA_HOME to Java 17 (required for PySpark 3.4+)\n",
    "os.environ[\"JAVA_HOME\"] = \"/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\"\n",
    "\n",
    "# Add parent directory to path to import config\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create Spark session for local execution\n",
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"FunnelPulse Batch Pipeline\")\n",
    "    .master(\"local[*]\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .config(\"spark.sql.shuffle.partitions\", \"200\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "\n",
    "print(spark)\n",
    "print(f\"Spark UI available at: http://localhost:4040\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "712bf4ea-50a5-49c5-b070-eb5bae3ecd23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project\n",
      "Raw dir     : /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/data_raw\n",
      "Bronze path : /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/tables/bronze_events\n",
      "Silver path : /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/tables/silver_events\n",
      "Gold path   : /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/tables/gold_funnel_hourly_brand\n"
     ]
    }
   ],
   "source": [
    "# CELL 2: Project paths configuration\n",
    "# Uses the project directory (parent of notebooks folder)\n",
    "\n",
    "import os\n",
    "\n",
    "# Get project root (parent directory of notebooks)\n",
    "project_root = os.path.dirname(os.getcwd())\n",
    "\n",
    "raw_dir    = os.path.join(project_root, \"data_raw\")\n",
    "tables_dir = os.path.join(project_root, \"tables\")\n",
    "\n",
    "bronze_path = os.path.join(tables_dir, \"bronze_events\")\n",
    "silver_path = os.path.join(tables_dir, \"silver_events\")\n",
    "gold_path   = os.path.join(tables_dir, \"gold_funnel_hourly_brand\")\n",
    "\n",
    "# Ensure directories exist\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "os.makedirs(tables_dir, exist_ok=True)\n",
    "\n",
    "print(\"Project root:\", project_root)\n",
    "print(\"Raw dir     :\", raw_dir)\n",
    "print(\"Bronze path :\", bronze_path)\n",
    "print(\"Silver path :\", silver_path)\n",
    "print(\"Gold path   :\", gold_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45f56995-bb1e-41d3-a0b5-022ce9e2aa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading single CSV: /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/data_raw/2019-Oct.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw schema:\n",
      "root\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- category_id: long (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- user_session: string (nullable = true)\n",
      "\n",
      "+-------------------+----------+----------+-------------------+-------------+------+-----+---------+------------------------------------+\n",
      "|event_time         |event_type|product_id|category_id        |category_code|brand |price|user_id  |user_session                        |\n",
      "+-------------------+----------+----------+-------------------+-------------+------+-----+---------+------------------------------------+\n",
      "|2019-09-30 20:00:00|cart      |5773203   |1487580005134238553|NULL         |runail|2.62 |463240011|26dd6e6e-4dac-4778-8d2c-92e149dab885|\n",
      "|2019-09-30 20:00:03|cart      |5773353   |1487580005134238553|NULL         |runail|2.62 |463240011|26dd6e6e-4dac-4778-8d2c-92e149dab885|\n",
      "|2019-09-30 20:00:07|cart      |5881589   |2151191071051219817|NULL         |lovely|13.48|429681830|49e8d843-adf3-428b-a2c3-fe8bc6a307c9|\n",
      "|2019-09-30 20:00:07|cart      |5723490   |1487580005134238553|NULL         |runail|2.62 |463240011|26dd6e6e-4dac-4778-8d2c-92e149dab885|\n",
      "|2019-09-30 20:00:15|cart      |5881449   |1487580013522845895|NULL         |lovely|0.56 |429681830|49e8d843-adf3-428b-a2c3-fe8bc6a307c9|\n",
      "+-------------------+----------+----------+-------------------+-------------+------+-----+---------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "Bronze exists: False\n",
      "Writing this month to BRONZE with mode: overwrite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing to BRONZE at: /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/tables/bronze_events\n",
      "Total BRONZE rows (all ingested months so far): 4102283\n",
      "+-------------------+----------+----------+-------------------+-------------+--------+-----+---------+------------------------------------+----------+\n",
      "|event_time         |event_type|product_id|category_id        |category_code|brand   |price|user_id  |user_session                        |event_date|\n",
      "+-------------------+----------+----------+-------------------+-------------+--------+-----+---------+------------------------------------+----------+\n",
      "|2019-10-02 00:00:00|view      |5877451   |1487580006300255120|NULL         |jessnail|44.29|544257140|2828b81d-89b3-4b25-96ae-15292222f338|2019-10-02|\n",
      "|2019-10-02 00:00:00|cart      |5692467   |1487580007852147670|NULL         |staleks |3.57 |555853251|46af5723-07da-4e6c-ad08-932f141a1410|2019-10-02|\n",
      "|2019-10-02 00:00:02|view      |5822415   |1487580013229244601|NULL         |NULL    |6.33 |514291330|394b16c3-7729-4abd-950a-2fe34fbd5d2e|2019-10-02|\n",
      "|2019-10-02 00:00:02|cart      |5867183   |1487580007852147670|NULL         |staleks |15.08|555853230|68c316dd-91c5-478f-9be0-f2c86935542a|2019-10-02|\n",
      "|2019-10-02 00:00:03|cart      |5742722   |1487580007852147670|NULL         |NULL    |5.71 |555853252|c15f60c0-aa29-4fcf-b970-0a4a177ebc99|2019-10-02|\n",
      "+-------------------+----------+----------+-------------------+-------------+--------+-----+---------+------------------------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# CELL 3: Ingest 2019-Oct CSV month into BRONZE (incremental)\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp, to_date, col\n",
    "\n",
    "# 1) Name of the file you've uploaded to data_raw\n",
    "single_csv_name = \"2019-Oct.csv\"   # change this for each month later\n",
    "single_csv_path = os.path.join(raw_dir, single_csv_name)\n",
    "\n",
    "print(\"Reading single CSV:\", single_csv_path)\n",
    "\n",
    "df_raw = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(single_csv_path)\n",
    ")\n",
    "\n",
    "print(\"Raw schema:\")\n",
    "df_raw.printSchema()\n",
    "df_raw.show(5, truncate=False)\n",
    "\n",
    "# 2) Normalize event_time and add event_date for partitioning\n",
    "df_bronze_month = (\n",
    "    df_raw\n",
    "    .withColumn(\"event_time\", to_timestamp(\"event_time\"))\n",
    "    .withColumn(\"event_date\", to_date(col(\"event_time\")))\n",
    ")\n",
    "\n",
    "# 3) Decide write mode: overwrite if bronze doesn't exist yet, append otherwise\n",
    "import pathlib\n",
    "\n",
    "bronze_exists = pathlib.Path(bronze_path).exists()\n",
    "write_mode = \"append\" if bronze_exists else \"overwrite\"\n",
    "\n",
    "print(\"Bronze exists:\", bronze_exists)\n",
    "print(\"Writing this month to BRONZE with mode:\", write_mode)\n",
    "\n",
    "(\n",
    "    df_bronze_month\n",
    "    .write\n",
    "    .mode(write_mode)\n",
    "    .partitionBy(\"event_date\")\n",
    "    .parquet(bronze_path)\n",
    ")\n",
    "\n",
    "print(\"Finished writing to BRONZE at:\", bronze_path)\n",
    "\n",
    "# 4) Quick check on total bronze rows so far\n",
    "bronze_check = spark.read.parquet(bronze_path)\n",
    "print(\"Total BRONZE rows (all ingested months so far):\", bronze_check.count())\n",
    "bronze_check.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3842f1f-333b-46a6-9a40-819d72d83c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading single CSV: /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/data_raw/2019-Nov.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw schema:\n",
      "root\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- category_id: long (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- user_session: string (nullable = true)\n",
      "\n",
      "+-------------------+----------------+----------+-------------------+-------------+--------+-----+---------+------------------------------------+\n",
      "|event_time         |event_type      |product_id|category_id        |category_code|brand   |price|user_id  |user_session                        |\n",
      "+-------------------+----------------+----------+-------------------+-------------+--------+-----+---------+------------------------------------+\n",
      "|2019-10-31 20:00:02|view            |5802432   |1487580009286598681|NULL         |NULL    |0.32 |562076640|09fafd6c-6c99-46b1-834f-33527f4de241|\n",
      "|2019-10-31 20:00:09|cart            |5844397   |1487580006317032337|NULL         |NULL    |2.38 |553329724|2067216c-31b5-455d-a1cc-af0575a34ffb|\n",
      "|2019-10-31 20:00:10|view            |5837166   |1783999064103190764|NULL         |pnb     |22.22|556138645|57ed222e-a54a-4907-9944-5a875c2d7f4f|\n",
      "|2019-10-31 20:00:11|cart            |5876812   |1487580010100293687|NULL         |jessnail|3.16 |564506666|186c1951-8052-4b37-adce-dd9644b1d5f7|\n",
      "|2019-10-31 20:00:24|remove_from_cart|5826182   |1487580007483048900|NULL         |NULL    |3.33 |553329724|2067216c-31b5-455d-a1cc-af0575a34ffb|\n",
      "+-------------------+----------------+----------+-------------------+-------------+--------+-----+---------+------------------------------------+\n",
      "only showing top 5 rows\n",
      "Bronze exists: True\n",
      "Writing this month to BRONZE with mode: append\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished writing to BRONZE at: /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/tables/bronze_events\n",
      "Total BRONZE rows (all ingested months so far): 8738120\n",
      "+-------------------+----------+----------+-------------------+-------------+-------+-----+---------+------------------------------------+----------+\n",
      "|event_time         |event_type|product_id|category_id        |category_code|brand  |price|user_id  |user_session                        |event_date|\n",
      "+-------------------+----------+----------+-------------------+-------------+-------+-----+---------+------------------------------------+----------+\n",
      "|2019-11-22 00:00:00|cart      |5794074   |1487580005511725929|NULL         |NULL   |5.27 |574742033|8c95bf39-00cb-40da-b050-9886ae81571a|2019-11-22|\n",
      "|2019-11-22 00:00:00|view      |5857360   |1487580008145748965|NULL         |runail |1.43 |567776789|c3e54af9-7253-435e-be00-3957dde96758|2019-11-22|\n",
      "|2019-11-22 00:00:00|cart      |5843548   |1487580010628776014|NULL         |NULL   |3.57 |531053364|9153fbde-8b08-4789-bca8-ca32be51d23a|2019-11-22|\n",
      "|2019-11-22 00:00:01|view      |5809912   |1602943681873052386|NULL         |grattol|5.24 |567594281|85557330-5a0e-512c-ef0f-e0884d3e2443|2019-11-22|\n",
      "|2019-11-22 00:00:01|cart      |5854897   |1487580009445982239|NULL         |irisk  |0.3  |512207618|82b43786-f811-45fe-962c-a4502158b43d|2019-11-22|\n",
      "+-------------------+----------+----------+-------------------+-------------+-------+-----+---------+------------------------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# CELL 3.1: Ingest 2019-Nov CSV month into BRONZE (incremental)\n",
    "\n",
    "from pyspark.sql.functions import to_timestamp, to_date, col\n",
    "\n",
    "# 1) Name of the file you've uploaded to data_raw\n",
    "single_csv_name = \"2019-Nov.csv\"   # change this for each month later\n",
    "single_csv_path = os.path.join(raw_dir, single_csv_name)\n",
    "\n",
    "print(\"Reading single CSV:\", single_csv_path)\n",
    "\n",
    "df_raw = (\n",
    "    spark.read\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .csv(single_csv_path)\n",
    ")\n",
    "\n",
    "print(\"Raw schema:\")\n",
    "df_raw.printSchema()\n",
    "df_raw.show(5, truncate=False)\n",
    "\n",
    "# 2) Normalize event_time and add event_date for partitioning\n",
    "df_bronze_month = (\n",
    "    df_raw\n",
    "    .withColumn(\"event_time\", to_timestamp(\"event_time\"))\n",
    "    .withColumn(\"event_date\", to_date(col(\"event_time\")))\n",
    ")\n",
    "\n",
    "# 3) Decide write mode: overwrite if bronze doesn't exist yet, append otherwise\n",
    "import pathlib\n",
    "\n",
    "bronze_exists = pathlib.Path(bronze_path).exists()\n",
    "write_mode = \"append\" if bronze_exists else \"overwrite\"\n",
    "\n",
    "print(\"Bronze exists:\", bronze_exists)\n",
    "print(\"Writing this month to BRONZE with mode:\", write_mode)\n",
    "\n",
    "(\n",
    "    df_bronze_month\n",
    "    .write\n",
    "    .mode(write_mode)\n",
    "    .partitionBy(\"event_date\")\n",
    "    .parquet(bronze_path)\n",
    ")\n",
    "\n",
    "print(\"Finished writing to BRONZE at:\", bronze_path)\n",
    "\n",
    "# 4) Quick check on total bronze rows so far\n",
    "bronze_check = spark.read.parquet(bronze_path)\n",
    "print(\"Total BRONZE rows (all ingested months so far):\", bronze_check.count())\n",
    "bronze_check.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60b35214-1b8b-423d-824f-1a0c4ade8bb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading bronze table from: /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/tables/bronze_events\n",
      "Bronze row count: 8738120\n",
      "+-------------------+----------+----------+-------------------+-------------+-------+-----+---------+------------------------------------+----------+\n",
      "|event_time         |event_type|product_id|category_id        |category_code|brand  |price|user_id  |user_session                        |event_date|\n",
      "+-------------------+----------+----------+-------------------+-------------+-------+-----+---------+------------------------------------+----------+\n",
      "|2019-11-22 00:00:00|cart      |5794074   |1487580005511725929|NULL         |NULL   |5.27 |574742033|8c95bf39-00cb-40da-b050-9886ae81571a|2019-11-22|\n",
      "|2019-11-22 00:00:00|view      |5857360   |1487580008145748965|NULL         |runail |1.43 |567776789|c3e54af9-7253-435e-be00-3957dde96758|2019-11-22|\n",
      "|2019-11-22 00:00:00|cart      |5843548   |1487580010628776014|NULL         |NULL   |3.57 |531053364|9153fbde-8b08-4789-bca8-ca32be51d23a|2019-11-22|\n",
      "|2019-11-22 00:00:01|view      |5809912   |1602943681873052386|NULL         |grattol|5.24 |567594281|85557330-5a0e-512c-ef0f-e0884d3e2443|2019-11-22|\n",
      "|2019-11-22 00:00:01|cart      |5854897   |1487580009445982239|NULL         |irisk  |0.3  |512207618|82b43786-f811-45fe-962c-a4502158b43d|2019-11-22|\n",
      "+-------------------+----------+----------+-------------------+-------------+-------+-----+---------+------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "Silver schema after cleaning:\n",
      "root\n",
      " |-- event_time: timestamp (nullable = true)\n",
      " |-- event_type: string (nullable = true)\n",
      " |-- product_id: integer (nullable = true)\n",
      " |-- category_id: long (nullable = true)\n",
      " |-- category_code: string (nullable = true)\n",
      " |-- brand: string (nullable = true)\n",
      " |-- price: double (nullable = true)\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- user_session: string (nullable = true)\n",
      " |-- event_date: date (nullable = true)\n",
      " |-- brand_norm: string (nullable = true)\n",
      " |-- category_code_norm: string (nullable = true)\n",
      " |-- dq_missing_session: boolean (nullable = false)\n",
      " |-- dq_missing_brand: boolean (nullable = false)\n",
      " |-- dq_missing_category: boolean (nullable = false)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+----------+-------+----------+-------------+------------------+------------------+----------------+\n",
      "|event_time         |event_type|brand  |brand_norm|category_code|category_code_norm|dq_missing_session|dq_missing_brand|\n",
      "+-------------------+----------+-------+----------+-------------+------------------+------------------+----------------+\n",
      "|2019-11-22 00:00:00|cart      |NULL   |NULL      |NULL         |NULL              |false             |true            |\n",
      "|2019-11-22 00:00:00|view      |runail |runail    |NULL         |NULL              |false             |false           |\n",
      "|2019-11-22 00:00:00|cart      |NULL   |NULL      |NULL         |NULL              |false             |true            |\n",
      "|2019-11-22 00:00:01|view      |grattol|grattol   |NULL         |NULL              |false             |false           |\n",
      "|2019-11-22 00:00:01|cart      |irisk  |irisk     |NULL         |NULL              |false             |false           |\n",
      "+-------------------+----------+-------+----------+-------------+------------------+------------------+----------------+\n",
      "only showing top 5 rows\n",
      "Row count before dedup: 8720392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row count after  dedup: 8260755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver table written to: /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/tables/silver_events\n",
      "Silver check row count: 8260755\n",
      "+-------------------+----------+----------+-------------------+-------------+--------+-----+---------+------------------------------------+----------+------------------+------------------+----------------+-------------------+----------+\n",
      "|event_time         |event_type|product_id|category_id        |category_code|brand   |price|user_id  |user_session                        |brand_norm|category_code_norm|dq_missing_session|dq_missing_brand|dq_missing_category|event_date|\n",
      "+-------------------+----------+----------+-------------------+-------------+--------+-----+---------+------------------------------------+----------+------------------+------------------+----------------+-------------------+----------+\n",
      "|2019-11-22 11:28:38|view      |5734492   |1487580005050352469|NULL         |haruyama|3.76 |228337277|000caab0-80fa-43ef-8abc-327ae98f2358|haruyama  |NULL              |false             |false           |true               |2019-11-22|\n",
      "|2019-11-22 13:45:57|view      |5751415   |1511892746070131099|NULL         |uno     |8.89 |389516574|000fb1c9-100a-40c4-8ae4-908ce6528c17|uno       |NULL              |false             |false           |true               |2019-11-22|\n",
      "|2019-11-22 04:25:13|view      |47611     |1487580007717929935|NULL         |NULL    |0.73 |163660246|0019d13a-a9ee-428e-b6ae-470b035b61f3|NULL      |NULL              |false             |true            |true               |2019-11-22|\n",
      "|2019-11-22 04:25:41|view      |82253     |1487580007717929935|NULL         |NULL    |0.67 |163660246|0019d13a-a9ee-428e-b6ae-470b035b61f3|NULL      |NULL              |false             |true            |true               |2019-11-22|\n",
      "|2019-11-22 04:26:15|view      |5645768   |1487580007717929935|NULL         |NULL    |1.54 |163660246|0019d13a-a9ee-428e-b6ae-470b035b61f3|NULL      |NULL              |false             |true            |true               |2019-11-22|\n",
      "+-------------------+----------+----------+-------------------+-------------+--------+-----+---------+------------------------------------+----------+------------------+------------------+----------------+-------------------+----------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# CELL 4: build SILVER (cleaned, normalized, DQ flags, deduped)\n",
    "\n",
    "from pyspark.sql.functions import lower, regexp_replace, when\n",
    "\n",
    "print(\"Reading bronze table from:\", bronze_path)\n",
    "bronze = spark.read.parquet(bronze_path)\n",
    "\n",
    "print(\"Bronze row count:\", bronze.count())\n",
    "bronze.show(5, truncate=False)\n",
    "\n",
    "silver = bronze\n",
    "\n",
    "# Drop obviously bad rows: null/<=0 price, null event_time or event_type\n",
    "silver = silver.filter(silver.price.isNotNull() & (silver.price > 0))\n",
    "silver = silver.filter(silver.event_time.isNotNull() & silver.event_type.isNotNull())\n",
    "\n",
    "# Normalize brand and category_code\n",
    "silver = (\n",
    "    silver\n",
    "    .withColumn(\"brand_norm\", lower(col(\"brand\")))\n",
    "    .withColumn(\"category_code_norm\", lower(col(\"category_code\")))\n",
    "    .withColumn(\n",
    "        \"category_code_norm\",\n",
    "        regexp_replace(col(\"category_code_norm\"), \"[^a-z0-9\\\\.]\", \"_\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Simple data quality flags\n",
    "silver = (\n",
    "    silver\n",
    "    .withColumn(\"dq_missing_session\", silver.user_session.isNull())\n",
    "    .withColumn(\"dq_missing_brand\", silver.brand.isNull())\n",
    "    .withColumn(\"dq_missing_category\", silver.category_code.isNull())\n",
    ")\n",
    "\n",
    "print(\"Silver schema after cleaning:\")\n",
    "silver.printSchema()\n",
    "\n",
    "silver.select(\n",
    "    \"event_time\", \"event_type\",\n",
    "    \"brand\", \"brand_norm\",\n",
    "    \"category_code\", \"category_code_norm\",\n",
    "    \"dq_missing_session\", \"dq_missing_brand\"\n",
    ").show(5, truncate=False)\n",
    "\n",
    "# Deduplicate on composite key\n",
    "dedup_cols = [\"event_time\", \"user_id\", \"user_session\", \"product_id\", \"event_type\"]\n",
    "silver_dedup = silver.dropDuplicates(dedup_cols)\n",
    "\n",
    "print(\"Row count before dedup:\", silver.count())\n",
    "print(\"Row count after  dedup:\", silver_dedup.count())\n",
    "\n",
    "# Write silver, partitioned by event_date (same as bronze)\n",
    "(\n",
    "    silver_dedup\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"event_date\")\n",
    "    .parquet(silver_path)\n",
    ")\n",
    "\n",
    "print(\"Silver table written to:\", silver_path)\n",
    "\n",
    "# Quick check\n",
    "silver_check = spark.read.parquet(silver_path)\n",
    "print(\"Silver check row count:\", silver_check.count())\n",
    "silver_check.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0c8382f-c1c5-4048-bbfe-e11e7d4c9a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silver row count: 8260755\n",
      "root\n",
      " |-- brand: string (nullable = true)\n",
      " |-- views: long (nullable = true)\n",
      " |-- carts: long (nullable = true)\n",
      " |-- purchases: long (nullable = true)\n",
      " |-- revenue: double (nullable = true)\n",
      " |-- window_start: timestamp (nullable = true)\n",
      " |-- window_end: timestamp (nullable = true)\n",
      " |-- view_to_cart_rate: double (nullable = true)\n",
      " |-- cart_to_purchase_rate: double (nullable = true)\n",
      " |-- conversion_rate: double (nullable = true)\n",
      " |-- window_date: date (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----+-----+---------+-----------------+-------------------+-------------------+-------------------+---------------------+-------------------+-----------+\n",
      "|brand      |views|carts|purchases|revenue          |window_start       |window_end         |view_to_cart_rate  |cart_to_purchase_rate|conversion_rate    |window_date|\n",
      "+-----------+-----+-----+---------+-----------------+-------------------+-------------------+-------------------+---------------------+-------------------+-----------+\n",
      "|NULL       |202  |185  |59       |284.0199999999999|2019-09-30 20:00:00|2019-09-30 21:00:00|0.9158415841584159 |0.31891891891891894  |0.29207920792079206|2019-09-30 |\n",
      "|airnails   |0    |2    |2        |2.38             |2019-09-30 20:00:00|2019-09-30 21:00:00|NULL               |1.0                  |NULL               |2019-09-30 |\n",
      "|ardell     |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|art-visage |2    |4    |2        |5.640000000000001|2019-09-30 20:00:00|2019-09-30 21:00:00|2.0                |0.5                  |1.0                |2019-09-30 |\n",
      "|beautix    |2    |2    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|1.0                |0.0                  |0.0                |2019-09-30 |\n",
      "|beauty-free|3    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|bioaqua    |1    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|1.0                |0.0                  |0.0                |2019-09-30 |\n",
      "|bluesky    |7    |4    |19       |81.77999999999999|2019-09-30 20:00:00|2019-09-30 21:00:00|0.5714285714285714 |4.75                 |2.7142857142857144 |2019-09-30 |\n",
      "|bpw.style  |3    |4    |6        |5.22             |2019-09-30 20:00:00|2019-09-30 21:00:00|1.3333333333333333 |1.5                  |2.0                |2019-09-30 |\n",
      "|browxenna  |2    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|cnd        |15   |5    |1        |15.71            |2019-09-30 20:00:00|2019-09-30 21:00:00|0.3333333333333333 |0.2                  |0.06666666666666667|2019-09-30 |\n",
      "|concept    |11   |5    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.45454545454545453|0.0                  |0.0                |2019-09-30 |\n",
      "|cosmoprofi |3    |4    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|1.3333333333333333 |0.0                  |0.0                |2019-09-30 |\n",
      "|cutrin     |0    |0    |1        |6.54             |2019-09-30 20:00:00|2019-09-30 21:00:00|NULL               |NULL                 |NULL               |2019-09-30 |\n",
      "|de.lux     |2    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |0.0                  |0.0                |2019-09-30 |\n",
      "|depilflax  |5    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|dizao      |1    |2    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|2.0                |0.0                  |0.0                |2019-09-30 |\n",
      "|domix      |2    |1    |1        |2.68             |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |1.0                  |0.5                |2019-09-30 |\n",
      "|emil       |0    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|NULL               |0.0                  |NULL               |2019-09-30 |\n",
      "|enas       |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "+-----------+-----+-----+---------+-----------------+-------------------+-------------------+-------------------+---------------------+-------------------+-----------+\n",
      "only showing top 20 rows\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold table written to: /Users/aranyaaryaman/Desktop/bigData 2/finalProject/Big-Data-Project/tables/gold_funnel_hourly_brand\n"
     ]
    }
   ],
   "source": [
    "# CELL 5: build GOLD table (hourly funnel metrics by brand)\n",
    "\n",
    "from pyspark.sql.functions import window, sum as _sum, to_date\n",
    "\n",
    "silver = spark.read.parquet(silver_path)\n",
    "\n",
    "print(\"Silver row count:\", silver.count())\n",
    "\n",
    "# Group by 1-hour windows and brand\n",
    "windowed = (\n",
    "    silver\n",
    "    .groupBy(\n",
    "        window(col(\"event_time\"), \"1 hour\").alias(\"w\"),\n",
    "        col(\"brand_norm\").alias(\"brand\")\n",
    "    )\n",
    "    .agg(\n",
    "        _sum((col(\"event_type\") == \"view\").cast(\"int\")).alias(\"views\"),\n",
    "        _sum((col(\"event_type\") == \"cart\").cast(\"int\")).alias(\"carts\"),\n",
    "        _sum((col(\"event_type\") == \"purchase\").cast(\"int\")).alias(\"purchases\"),\n",
    "        _sum(\n",
    "            when(col(\"event_type\") == \"purchase\", col(\"price\")).otherwise(0.0)\n",
    "        ).alias(\"revenue\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Flatten the window struct\n",
    "gold = (\n",
    "    windowed\n",
    "    .withColumn(\"window_start\", col(\"w.start\"))\n",
    "    .withColumn(\"window_end\", col(\"w.end\"))\n",
    "    .drop(\"w\")\n",
    ")\n",
    "\n",
    "# Funnel rates with divide-by-zero protection\n",
    "gold = (\n",
    "    gold\n",
    "    .withColumn(\n",
    "        \"view_to_cart_rate\",\n",
    "        when(col(\"views\") > 0, col(\"carts\") / col(\"views\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"cart_to_purchase_rate\",\n",
    "        when(col(\"carts\") > 0, col(\"purchases\") / col(\"carts\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"conversion_rate\",\n",
    "        when(col(\"views\") > 0, col(\"purchases\") / col(\"views\"))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Partition by date of window_start\n",
    "gold = gold.withColumn(\"window_date\", to_date(col(\"window_start\")))\n",
    "\n",
    "gold.printSchema()\n",
    "gold.orderBy(\"window_start\", \"brand\").show(20, truncate=False)\n",
    "\n",
    "# Write gold table\n",
    "(\n",
    "    gold\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .partitionBy(\"window_date\")\n",
    "    .parquet(gold_path)\n",
    ")\n",
    "\n",
    "print(\"Gold table written to:\", gold_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4da4e960-d443-48e3-9d0e-bff8f4763ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gold rows: 183145\n",
      "+-----------+-----+-----+---------+-----------------+-------------------+-------------------+-------------------+---------------------+-------------------+-----------+\n",
      "|brand      |views|carts|purchases|revenue          |window_start       |window_end         |view_to_cart_rate  |cart_to_purchase_rate|conversion_rate    |window_date|\n",
      "+-----------+-----+-----+---------+-----------------+-------------------+-------------------+-------------------+---------------------+-------------------+-----------+\n",
      "|NULL       |202  |185  |59       |284.0199999999999|2019-09-30 20:00:00|2019-09-30 21:00:00|0.9158415841584159 |0.31891891891891894  |0.29207920792079206|2019-09-30 |\n",
      "|airnails   |0    |2    |2        |2.38             |2019-09-30 20:00:00|2019-09-30 21:00:00|NULL               |1.0                  |NULL               |2019-09-30 |\n",
      "|ardell     |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|art-visage |2    |4    |2        |5.640000000000001|2019-09-30 20:00:00|2019-09-30 21:00:00|2.0                |0.5                  |1.0                |2019-09-30 |\n",
      "|beautix    |2    |2    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|1.0                |0.0                  |0.0                |2019-09-30 |\n",
      "|beauty-free|3    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|bioaqua    |1    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|1.0                |0.0                  |0.0                |2019-09-30 |\n",
      "|bluesky    |7    |4    |19       |81.77999999999999|2019-09-30 20:00:00|2019-09-30 21:00:00|0.5714285714285714 |4.75                 |2.7142857142857144 |2019-09-30 |\n",
      "|bpw.style  |3    |4    |6        |5.22             |2019-09-30 20:00:00|2019-09-30 21:00:00|1.3333333333333333 |1.5                  |2.0                |2019-09-30 |\n",
      "|browxenna  |2    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|cnd        |15   |5    |1        |15.71            |2019-09-30 20:00:00|2019-09-30 21:00:00|0.3333333333333333 |0.2                  |0.06666666666666667|2019-09-30 |\n",
      "|concept    |11   |5    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.45454545454545453|0.0                  |0.0                |2019-09-30 |\n",
      "|cosmoprofi |3    |4    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|1.3333333333333333 |0.0                  |0.0                |2019-09-30 |\n",
      "|cutrin     |0    |0    |1        |6.54             |2019-09-30 20:00:00|2019-09-30 21:00:00|NULL               |NULL                 |NULL               |2019-09-30 |\n",
      "|de.lux     |2    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |0.0                  |0.0                |2019-09-30 |\n",
      "|depilflax  |5    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|dizao      |1    |2    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|2.0                |0.0                  |0.0                |2019-09-30 |\n",
      "|domix      |2    |1    |1        |2.68             |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |1.0                  |0.5                |2019-09-30 |\n",
      "|emil       |0    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|NULL               |0.0                  |NULL               |2019-09-30 |\n",
      "|enas       |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|entity     |8    |4    |1        |1.11             |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |0.25                 |0.125              |2019-09-30 |\n",
      "|estel      |6    |6    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|1.0                |0.0                  |0.0                |2019-09-30 |\n",
      "|f.o.x      |4    |3    |3        |18.09            |2019-09-30 20:00:00|2019-09-30 21:00:00|0.75               |1.0                  |0.75               |2019-09-30 |\n",
      "|farmstay   |0    |4    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|NULL               |0.0                  |NULL               |2019-09-30 |\n",
      "|freedecor  |1    |0    |7        |5.53             |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |7.0                |2019-09-30 |\n",
      "|grattol    |10   |5    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |0.0                  |0.0                |2019-09-30 |\n",
      "|haruyama   |2    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |0.0                  |0.0                |2019-09-30 |\n",
      "|ingarden   |4    |5    |2        |1.58             |2019-09-30 20:00:00|2019-09-30 21:00:00|1.25               |0.4                  |0.5                |2019-09-30 |\n",
      "|irisk      |11   |20   |8        |36.97            |2019-09-30 20:00:00|2019-09-30 21:00:00|1.8181818181818181 |0.4                  |0.7272727272727273 |2019-09-30 |\n",
      "|italwax    |8    |4    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |0.0                  |0.0                |2019-09-30 |\n",
      "|jas        |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|jessnail   |10   |3    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.3                |0.0                  |0.0                |2019-09-30 |\n",
      "|kaaral     |2    |2    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|1.0                |0.0                  |0.0                |2019-09-30 |\n",
      "|kapous     |16   |4    |2        |5.62             |2019-09-30 20:00:00|2019-09-30 21:00:00|0.25               |0.5                  |0.125              |2019-09-30 |\n",
      "|kaypro     |2    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|keen       |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|kinetics   |6    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|kiss       |11   |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|kosmekka   |0    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|NULL               |0.0                  |NULL               |2019-09-30 |\n",
      "|levrana    |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|lianail    |3    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.3333333333333333 |0.0                  |0.0                |2019-09-30 |\n",
      "|likato     |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|limoni     |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|lovely     |2    |3    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|1.5                |0.0                  |0.0                |2019-09-30 |\n",
      "|markell    |1    |0    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.0                |NULL                 |0.0                |2019-09-30 |\n",
      "|masura     |5    |9    |1        |15.54            |2019-09-30 20:00:00|2019-09-30 21:00:00|1.8                |0.1111111111111111   |0.2                |2019-09-30 |\n",
      "|matrix     |2    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |0.0                  |0.0                |2019-09-30 |\n",
      "|mavala     |0    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|NULL               |0.0                  |NULL               |2019-09-30 |\n",
      "|max        |3    |1    |1        |47.46            |2019-09-30 20:00:00|2019-09-30 21:00:00|0.3333333333333333 |1.0                  |0.3333333333333333 |2019-09-30 |\n",
      "|metzger    |2    |1    |0        |0.0              |2019-09-30 20:00:00|2019-09-30 21:00:00|0.5                |0.0                  |0.0                |2019-09-30 |\n",
      "+-----------+-----+-----+---------+-----------------+-------------------+-------------------+-------------------+---------------------+-------------------+-----------+\n",
      "only showing top 50 rows\n",
      "+--------+------------------+\n",
      "|brand   |total_revenue     |\n",
      "+--------+------------------+\n",
      "|NULL    |1094863.58        |\n",
      "|runail  |148254.68000000002|\n",
      "|grattol |106918.24999999999|\n",
      "|irisk   |92470.88999999997 |\n",
      "|uno     |86341.77999999998 |\n",
      "|strong  |67867.90000000001 |\n",
      "|masura  |63722.51999999999 |\n",
      "|jessnail|59633.07          |\n",
      "|cnd     |59240.77          |\n",
      "|ingarden|56696.96000000001 |\n",
      "+--------+------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# CELL 6: verify GOLD and do a simple analytic query\n",
    "\n",
    "gold_check = spark.read.parquet(gold_path)\n",
    "\n",
    "print(\"Gold rows:\", gold_check.count())\n",
    "\n",
    "# Show a few rows ordered by time and brand\n",
    "gold_check.orderBy(\"window_start\", \"brand\").show(50, truncate=False)\n",
    "\n",
    "# Example: top 10 brands by total revenue across all windows\n",
    "from pyspark.sql.functions import desc\n",
    "\n",
    "gold_check.groupBy(\"brand\").agg(\n",
    "    _sum(\"revenue\").alias(\"total_revenue\")\n",
    ").orderBy(desc(\"total_revenue\")).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87566389-c0d1-47a3-8b4c-9e1ac5fc3b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
